{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4312559e-bc43-4820-a903-d0d09c4c1cfc",
   "metadata": {},
   "source": [
    "# Key Points\n",
    "**Table of Content**\n",
    "1. [Python Utils](#Python-Utilitities)\n",
    "    1. [Markdown](#Markdown-tutorial)\n",
    "    1. [Print](#Print)\n",
    "    1. [Logging](#Logging)\n",
    "1. [Integer](#Integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99b761-7dcc-4b18-8bdb-69750fe10e89",
   "metadata": {},
   "source": [
    "# Python Utilitities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6985b97-31df-44a1-99b3-913cc7615cc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Markdown tutorial\n",
    "```\n",
    "**Bold** - bold charatcer\n",
    "*Italic* - Italic charater\n",
    "_Italic_ - italic character\n",
    "**_bold and italic_** - both bold and italic\n",
    "\n",
    "1. - Numbering, sub heads with indentation\n",
    "-  - bullets, sub heads with indentation\n",
    "\n",
    "''' ''' (back ticks) - python code visualization\n",
    "\n",
    "```\n",
    "Paragraph breaks\n",
    "- soft break done by putting **two spaces** at the end of line\n",
    "- hard break  by adding a blank line\n",
    "\n",
    "Block quotes\n",
    "> this is   \n",
    "block quote\n",
    "\n",
    "to put up links\n",
    "[Google](google.com)\n",
    "\n",
    "Adding image\n",
    "![python Logo](https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg)\n",
    "<div>\n",
    "<img src=\"https://www.alpharithms.com/wp-content/uploads/1156/covariance-equation-diagram.jpg\" width=\"300\"/>\n",
    "</div>\n",
    "triple star to make a line separator\n",
    "```\n",
    "***\n",
    "```\n",
    "<span style=\"color:red\">Red color text</span>\n",
    "<span style=\"font-family:verdana\"> verdana font</span>\n",
    "\n",
    "\n",
    "---\n",
    "line breaker\n",
    "\n",
    "writing python code\n",
    "```py\n",
    "x=func(name)\n",
    "print(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538dc87-9d50-4ad4-8660-603809e7ec4c",
   "metadata": {},
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\WIN-10\\Downloads\\Study Materials-20230904T035822Z-001\\Study Materials\")\n",
    "ls\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15759f83-6805-4dd3-b534-2a966bf450f9",
   "metadata": {},
   "source": [
    "```\n",
    "print(locals()) # local variables\n",
    "print(globals()) # global varible\n",
    "print(dir()) # built in var and function\n",
    "locals().clear()\n",
    "globals().clear()\n",
    "%reset\n",
    "who\n",
    "whos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98247b-adc6-45ce-b911-cb826bee8cf2",
   "metadata": {},
   "source": [
    "## Print  \n",
    "[print tut link](https://realpython.com/python-print/)  \n",
    "\n",
    "print(\"hello\")    \n",
    "print(\"hello\",\"world\") # space is added automatically  \n",
    "\n",
    "**sep**  \n",
    "print(\"hello\",\"world\",sep=\"##\")# now the separator is ##  \n",
    "print(\"hello\",45) # it will work  \n",
    "print(\"hello\"+45) will not work because Python is a strongly typed language, which means it won’t allow you to do this  \n",
    "\n",
    "**end**  \n",
    "print('The first sentence', end='. ')  \r\n",
    "print('The second sentence', end='. '  )\r\n",
    "print('The last sentenc'.\n",
    "\n",
    "**pprint**  \n",
    "from pprint import pprint  \n",
    "a={'power':[x**10 for x in range(10)]}  \n",
    "print(a)  \n",
    "pprint(a)  \n",
    "\n",
    "**format**  \n",
    "print('I love {} for \"{}!\"'.format('Geeks', 'Geeks'))  \n",
    "\n",
    "# using format() method and referring a position of the obje  ct\r\n",
    "print('{0} and {1}'.format('Geeks', 'Portal  '))\r\n",
    " \r\n",
    "print('{1} and {0}'.format('Geeks', 'Port  al'))\r\n",
    " \r\n",
    "print(f\"I love {'Geeks'} for \\\"{'Geeks  '\n",
    "using \n",
    "# using format() method and referring a position of t  he object\r\n",
    "print(f\"{'Geeks'} and {'  Portal'}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfbe26d-8832-4760-9250-45021d6a5d5f",
   "metadata": {},
   "source": [
    "### os  \n",
    "#directory name  \n",
    "os.path.dirname(\"python_coding/Tensor_tut/NLP_tut.ipynb\")\n",
    "\n",
    "#making directories\n",
    "os.makedirs(\"path\",exist_ok=True) \n",
    "#throws no error if the directory already exists\n",
    "\n",
    "#if directory exits\n",
    "os.path.exists(\"data2\")\n",
    "\n",
    "#make 100 directories inside a directory\n",
    "os.path.exists('data1')\n",
    "for i in range(100):\n",
    "    os.makedirs(f\"data1\\\\day{i}\")\n",
    "\n",
    "#rename folder\n",
    "for i in range(50):\n",
    "    os.rename(f\"data1\\\\day{i}\",f\"data1\\\\tutorial{i}\")\n",
    "\n",
    "#listing folders\n",
    "folder = os.listdir(\"data1\")\n",
    "print(folder)\n",
    "or\n",
    "for f in folders:\n",
    "    print(f)\n",
    "#files in subfolder\n",
    "for f in fol:\n",
    "    print(os.listdir(f\"data1\\\\{f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b226aeb-2187-4f52-a324-17c06ff0cef3",
   "metadata": {},
   "source": [
    "## Logging\n",
    "```py\n",
    "import logging  \n",
    "logging.basicConfig(filename='test.log',level=logging.INFO)  \n",
    "```\n",
    "#modify filename, format for custom logging  \n",
    "\n",
    "code\n",
    "```\n",
    "for f in fol:\n",
    "    x=os.listdir(f\"data1\\\\{f}\")\n",
    "    logging.info(f\"logging info {f}\")\n",
    "    if len(a)!=0:\n",
    "        for i in x:\n",
    "            logging.info(f\"logging info file {f} {i}\")\n",
    "            print(i)\n",
    "```\n",
    "\n",
    "file will be created with the logs\n",
    "\n",
    "check formatters in logging docs. Specifically the lineno and pathname variables.\r\n",
    "\r\n",
    "%(pathname)s Full pathname of the source file where the logging call was issued(if available).\r\n",
    "\r\n",
    "%(filename)s Filename portion of pathname.\r\n",
    "\r\n",
    "%(module)s Module (name portion of filename).\r\n",
    "\r\n",
    "%(funcName)s Name of function containing the logging call.\r\n",
    "\r\n",
    "%(lineno)d Source line number where the logging call was issued (if available).\r\n",
    "\r\n",
    "Looks somethi\n",
    "formatter = logging.Formatter('[%(asctime)s] p%(process)s {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s','%m-%d %H:%M:%S')\n",
    "\n",
    "---\n",
    "\n",
    "```py\n",
    "\n",
    "import logging\r\n",
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "file_name = os.path.join(\"logs\", \"test.log\")\r\n",
    "file_dir = os.path.dirname(file_name)\r\n",
    "os.makedirs(file_dir, exist_ok=True)\r\n",
    "curr_file = os.path.basename(sys.argv[0])\r\n",
    "\r\n",
    "logging.basicConfig(\r\n",
    "    filename=file_name,\r\n",
    "    format=\"%(asctime)s %(levelname)s %(filename)s %(message)s\",\r\n",
    "    datefmt=\"%d/%m/%Y %H:%M:%S\",\r\n",
    "    level=logging.INFO,\r\n",
    "    \n",
    "```filemode=\"w\"\r\n",
    ")g like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdecbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the ASCII value\n",
    "print(ord('A'))\n",
    "to print ascii to unicode\n",
    "print(chr(97))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2035b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the charactestic and methods \n",
    "print(dir(math))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3584611",
   "metadata": {},
   "source": [
    "### types of operation\n",
    "\n",
    "- Arithmetic: +,-,*,/,//,**,%     (import math for ceil,floor)\n",
    "- comparison operator: <,>,<=,>=\n",
    "- equality operator:  ==, !=\n",
    "- logical operator and, or, not\n",
    "- bitwise operator &,|,~,^\n",
    "- Identity operator is, is not\n",
    "- assignment operator +="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f26388",
   "metadata": {},
   "source": [
    "### output of logical operator in print\n",
    "- print(A and B) : output is A if A is false, else B\n",
    "- print(A or B) : output is A if A is true, else B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff44bd",
   "metadata": {},
   "source": [
    "## Integer\n",
    "part 2, 24th jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfe1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical operator\n",
    "# and, or , not\n",
    "True and False\n",
    "not False\n",
    "bool(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f65018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise operator\n",
    "&(and),|(or),^(xor),<<(leftshift),>>(rightshift),~(not)\n",
    "bin(10)\n",
    "leftshift A * (2**n)\n",
    "rightshift A //(2**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc66e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment operator\n",
    "=\n",
    "x+=2  # _,/,//,**.&,|,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f426373",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identity operators\n",
    "- is\n",
    "- is not\n",
    "Note: tells if meo\\mory address of any 2 varible is same or not \n",
    "    will always return bool values\n",
    "object reusablity for int is -5 to 256  ( linked to RGB vlaues definition)\n",
    "works for bool, None, strings A-Z a-z 0-9 _\n",
    "\n",
    "does not work for float, complex, string with special char\n",
    "\n",
    "stack memory or varible memory and Heap memory\n",
    "for any variable assignment\n",
    "name is stored in stack and value is stored in heap\n",
    "name is assigned the address of value in heap\n",
    "\n",
    "a= 10\n",
    "b=20\n",
    "c=10\n",
    "print(id(a))\n",
    "print(id(b))\n",
    "print(id(c)) will be same as a\n",
    "\n",
    "print(a is b) False\n",
    "print(a is c) True\n",
    "print(a == c) True but its different from previous statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4ae81",
   "metadata": {},
   "source": [
    "### Float\n",
    "\n",
    "possible operation\n",
    "- Arithmetic operation (all operations are possible)\n",
    "- comparison operator\n",
    "- logical\n",
    "- assignment except bitwise\n",
    "- Identity operator\n",
    "\n",
    "Not possible\n",
    "- Bitwise\n",
    "- assignment with bitwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7b453",
   "metadata": {},
   "source": [
    "### Complex\n",
    "any number written in the form of a+bj\n",
    "a=4+7j\n",
    "print(a.real), print(a.imag)\n",
    "\n",
    "Operation possible \n",
    "- Arithmatic (modulo(%), floor division(//) will not work)\n",
    "- Logical\n",
    "- equality\n",
    "- Assignment\n",
    "- Identity (object reusability not applicable)\n",
    "\n",
    "Not possible\n",
    "- bitwise\n",
    "- comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c5ba4",
   "metadata": {},
   "source": [
    "### Strings\n",
    "- Anything written inside '',\"\",'''''',\"\"\"\"\"\"\n",
    "a= 'python'; print(a,type(a))\n",
    "\n",
    "It is a sequence data type\n",
    "(indexing is extracting one character at a time)\n",
    "(slicing is extracting multiple character at a time)\n",
    "- allows two things 1. +ve and -ve indexing 2. Slicing \n",
    "\n",
    "a[::]- (read L- R) - default value is 1, hence start is having default value as 0\n",
    "a[::-1] (read R - L)- since step is -1, hence start is having default value as -1, and the string is reversed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9adff4",
   "metadata": {},
   "source": [
    "### String part 2, 25th Jan\n",
    "Properties of string\n",
    "- string is a sequence data type --> +ve and -ve indexing\n",
    "- indexing - accessing one char at a time\n",
    "- slicing - accessing multiple char at a time\n",
    "- concatination, repeatition, Membership, identity operator\n",
    "\n",
    "string is an immutable data type\n",
    "\n",
    "#### concatination\n",
    "merging two or more strings together\n",
    "op +\n",
    "operands - both should be string\n",
    "\n",
    "a='data';b='science';print(a+b)\n",
    "\n",
    "#### repeatition\n",
    "op *\n",
    "operand - sring and integer(must)\n",
    "a='a';b=3;print(a*b)\n",
    "\n",
    "#### Identity operator\n",
    "is, is not, id()\n",
    "a-z A-Z 0-9 _ \n",
    "No special character\n",
    "\n",
    "#### Memebership operator\n",
    "op - in , not in\n",
    "if a substring is present in seq or not\n",
    "always returns bool values\n",
    "\n",
    "a='the course is python'\n",
    "b='is'\n",
    "print(b in a)\n",
    "\n",
    "eg\n",
    "a='10'\n",
    "b='10'\n",
    "print(a==b) # equality\n",
    "print(a is b) # identity\n",
    "print(a in b) # membership\n",
    "\n",
    "String is immutable\n",
    "Once decalred, it cannot be updated or changed\n",
    "\n",
    "#### Functions in string\n",
    "print(dir(str))\n",
    "a='this is python class'\n",
    "a.replace('x','y')\n",
    "a.capitalize() # it will convert the first char of the string to capital and remaining char to small\n",
    "a.upper() # convert all char to upper case\n",
    "a.lower() # convert all char to lower case\n",
    "a.title() # first char of all word to upper and rest all to lower\n",
    "\n",
    "Returns True and False only\n",
    "a.startswith('t'),a.startswith('thi')->True,a.startswith('hel',6)-->False\n",
    "a.endswith('s'),a.endswith('class'),a.endswith('s',0,4)\n",
    "a.isalnum() # returns true if the string is alpha numeric\n",
    "a.isalpha() # if all chars are alphabets\n",
    "a.isnumeric() # if all chars are numeric\n",
    "a.isidentifier() # checks if the string qualifies to be an identifier\n",
    "a.isascii() # if something is written in different language\n",
    "a.isupper() # if all chars are upper\n",
    "a.islower()\n",
    "a.istitle()\n",
    "a='abc'\n",
    "print(list(enumerate(a)))\n",
    "\n",
    "#### special char and escape function\n",
    "\\n : new line\n",
    "\\t : tab space\n",
    "\\b : backspace\n",
    "escape char \\\n",
    "a='hello\\\\tworld'\n",
    "raw string\n",
    "r'abcde'\n",
    "carriage return # moves the char on right hand side to left (replacing it)\n",
    "a='hello\\rwor' -> worlo\n",
    "\n",
    "#### strip, lstrip,rstrip\n",
    "print('     python    '.strip())\n",
    "print('****python***'.strip(*))\n",
    "print('****###python###***'.strip(*#))\n",
    "print('****#**##python###*#####**'.strip('*#'))\n",
    "strip removes specified char from both side, default char is space\n",
    "rstrip : removes from right side only\n",
    "lstrip : removes from left side only\n",
    "\n",
    "#### count\n",
    "a='python is a programming language, python has easy sysntax'\n",
    "a.count('p')\n",
    "a.count('python')\n",
    "\n",
    "#### find,rfind, index, rindex\n",
    "a.find('p')\n",
    "a.find('prog')\n",
    "a.rfind('p')\n",
    "a.index('p') # same result as find\n",
    "a.index('prog')\n",
    "a.rindex('p')\n",
    "\n",
    "difference is when the the specified string is not present\n",
    "find will give -1 as answer\n",
    "and index will throw an error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ddc87",
   "metadata": {},
   "source": [
    "#### String part 3, 27th jan\n",
    "**rjust, ljust**\n",
    "- to keep the lenght of string fixed\n",
    "a=hello\n",
    "a.rjust(10,'*')\n",
    "**Replace**\n",
    "a='python is a prog language'\n",
    "a.replace('python','java')\n",
    "a.replace('python','java',2) # only replace for two occurences\n",
    "\n",
    "**Split**\n",
    "it converts the string into a list based on specified char, default is space\n",
    "a='python is a prog language'\n",
    "a.split()\n",
    "a='hello*world'\n",
    "a.split('*')\n",
    "\n",
    "**Join**\n",
    "a='hello*world'\n",
    "b=a.split('*')\n",
    "'$$'.join(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc2139",
   "metadata": {},
   "source": [
    "#### List\n",
    "its a derived data type\n",
    "- any element written in [] and separated by ,\n",
    "#### creation of list\n",
    "1. a=[1,2,3,4,5]\n",
    "2. input from user\n",
    "a=eval(input('enter a list: ')) # give input in the form of list e.g. [1,2,3,4,5]\n",
    "3. typecasting\n",
    "a='abc'\n",
    "b=(1,2,3)\n",
    "print(list(a)) # string to list\n",
    "print(list(b)) # tuple to list\n",
    "4. a='python is a prog language'\n",
    "a.split()\n",
    "\n",
    "#### Properties of list\n",
    "- its a seq data type\n",
    "- indexing\n",
    "- slicing\n",
    "- both +ve and -ve indexing is possible\n",
    "- allows duplication\n",
    "- it is homogeneous, ie.e can store different data type\n",
    "- basic op concatination, repeatation, identity, memebership\n",
    "\n",
    "**concatination**\n",
    "a=[1,2,3]\n",
    "b=[4,5,6]\n",
    "c=a+b\n",
    "**repeatation**\n",
    "c=3*a\n",
    "**Identity**\n",
    "print(id(a))\n",
    "print(a is b) -> False\n",
    "**membership**\n",
    "in , not in\n",
    "print(2 in a) # True\n",
    "\n",
    "**Methods**\n",
    "to add elements to the list\n",
    "- append\n",
    "- extend\n",
    "- insert\n",
    "a=[1,2,3,4]\n",
    "a.append(6) # can add only one element at a time\n",
    "append also creates nested list\n",
    "b=[7,8,9]\n",
    "a.extend(b)\n",
    "Insert\n",
    "only one element can be inserted\n",
    "a=[1,2,3,4]\n",
    "a.insert(2,5) # inserted at 2nd place \n",
    "a.insert(2,[3,4,5]) # nested loop\n",
    "\n",
    "methods to remove the element from the list\n",
    "a.pop() # removes the last element\n",
    "a.pop(1) # with index also it can remove\n",
    "remove\n",
    "a=['a',2,'r']\n",
    "a.remove('a')\n",
    "\n",
    "**count**\n",
    "a=[1,2,2,2,2,3,4,2,5]\n",
    "a.count(2) -> 5\n",
    "\n",
    "**index**\n",
    "a=['a',2,'r']\n",
    "a.index('r') -> 2\n",
    "\n",
    "**reverse**\n",
    "a=['a',2,'r']\n",
    "a.reverse()\n",
    "\n",
    "**sort**\n",
    "a=[23,1,23,4,45,5,6,7,7,59]\n",
    "a.sort() #ascending order\n",
    "a.sort(reverse=True) # descending order\n",
    "a.sort(key=len) # pass a function in place of key\n",
    "\n",
    "**clear**\n",
    "a.clear() # deletes element and returns the empty list variable\n",
    "del a # deletes whole list and variable\n",
    "\n",
    "**delete**\n",
    "a=['a',2,'r']\n",
    "a.pop(index) # index 0,1,-1 etc\n",
    "a.pop(-1) # removes last element\n",
    "\n",
    "del a[index]\n",
    "\n",
    "a.remove('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de1aa4",
   "metadata": {},
   "source": [
    "### List part 2\n",
    "Aliasing, shallow copy, deep copy\n",
    "**Aliasing** # aliasing works for any sequencing data type\n",
    "a=[1,2,3,4,5]\n",
    "b=a\n",
    "print(id(a))\n",
    "print(id(b)) # pointing to same memory address, changing any one list will reflect in both variable\n",
    "**shallow copy**\n",
    "b=a.copy() # nested list will be aliased  \n",
    "\n",
    "**deep copy**\n",
    "from copy import deepcopy\n",
    "b=deepcopy(a) # even nested list will have different memory address\n",
    "\n",
    "**list comprehension**\n",
    "How to indetify if a datatype is iterable in for loop\n",
    "1. len function should work\n",
    "2. in print(dir()), __iter__ property should be there\n",
    "\n",
    "its replacement for 'for' loop\n",
    "syntax:\n",
    "[expression for var in iterable if condition]\n",
    "y = [x.filter_function for x in list] # will append x in y automatically\n",
    "a=list(range(20))\n",
    "out=[i for i in a if i%2==0]\n",
    "print(out)\n",
    "\n",
    "In general,\n",
    "\n",
    "[f(x) if condition else g(x) for x in sequence]\n",
    "And, for list comprehensions with if conditions only,\n",
    "\n",
    "[f(x) for x in sequence if condition]\n",
    "\n",
    "\n",
    "#### tuple\n",
    "\n",
    "anything written inside ()\n",
    "creating a tuple\n",
    "1. a=(1,2,3,4)\n",
    "2. a=eval(input()) -> entering input as comma sepearated will make a tuple\n",
    "3. typecasting\n",
    "b=tuple(a)\n",
    "4 a=1,2,3,4,5 # tuple packing, assigning multiple values to a single variable\n",
    "\n",
    "**Properties of tuple**\n",
    "- seq data type\n",
    "- indexing +ve, -ve\n",
    "- slicing\n",
    "- it is heterogeneous -> can hold any data type\n",
    "- allows dupolication\n",
    "- it is immutable\n",
    "- basic op concatination,repeatation, identity, membership\n",
    "**methods**\n",
    "count, index of specific elements\n",
    "a.count(1)\n",
    "a.index(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56e6e0",
   "metadata": {},
   "source": [
    "#### Dictionary 31st jan\n",
    "\n",
    "**tuple packing and unpacking**\n",
    "```\n",
    "packing -> assigning multiple values to a single variable\n",
    "a=2,3,4,5\n",
    "unpacking -> assigning multiple to multiple variable\n",
    "a,b=4,8 # number of var on left and right side should be equal\n",
    "\n",
    "a='python'\n",
    "for i in enumerate(a):\n",
    "    print(i)\n",
    "```\n",
    "**Dictionary**\n",
    "its not a sequence data type  \n",
    "its structured data type  \n",
    "\n",
    "emp_data={'name':'asdfh','age':40} # key:value pair  \n",
    "print(emp_data['name']  \n",
    "\n",
    "**properties**\n",
    "- it is a collection of key value pair\n",
    "- a key,value is called an item\n",
    "- items are seperated by comma\n",
    "- key and value are serparated by :\n",
    "- key cannot be duplicate, value can be duplicate. if key is repeated, then the last key is used\n",
    "- key has to be a immutable data type\n",
    "    - key can \n",
    "        - int\n",
    "        - float\n",
    "        - string\n",
    "        - bool\n",
    "        - tuple\n",
    "        - complex\n",
    "    - cannot be\n",
    "        - list\n",
    "        - dict\n",
    "        - arrays\n",
    "- **Strings and tuples are immutable, while lists, dictionaries, and sets are mutable.** \n",
    "- value can be mutable as well as immutable\n",
    "- inside {}\n",
    "- not seq data type, hence concatenation, indexing, slicing, repeatation not possible\n",
    "- membership on key only\n",
    "- identity posible\n",
    "\n",
    "**creating dictionary**\n",
    "```\n",
    "1. emp_data={'name':'asdfh','age':40}\n",
    "2. input a dictionary and use eval function\n",
    "3. typecasting\n",
    "b=[['a':3],['b':678]]\n",
    "dict(b)\n",
    "4. Zip function\n",
    "a=['a','b','c']\n",
    "b=[3,5,7]\n",
    "zip(iter1,iter2)\n",
    "dict(zip(iter1,iter2))\n",
    "```\n",
    "\n",
    "**updating the dictionary**\n",
    "emp_data={'name':'asdfh','age':40}\n",
    "emp_data['name']='dfkj'  # it will update the value\n",
    "emp_data['asd'] = 'dsdg' # it will add new key value\n",
    "\n",
    "\n",
    "**methods**\n",
    "1. get\n",
    "    if key is present\n",
    "        emp_data.get('name') -> 'dfkj'\n",
    "    if key is not present it will throw None\n",
    "        emp_data.get('name','message if key is not present')\n",
    "2. setdefault\n",
    "    if key is present\n",
    "        emp_data.setdefault('name')  # it will give the name\n",
    "    if key is not present it will throw None\n",
    "        will add the new key with None value\n",
    "        emp_data.setdefault('name','sdhj') # instead of None, the give value is set\n",
    "3. update\n",
    "    a=dictionary\n",
    "    b=dictionary\n",
    "    a.update(b) # will append the new dictionary, if key is different, else will update the existing key value\n",
    "4. Methods to remove element from dictionary\n",
    "    pop\n",
    "        if key is present\n",
    "            emp_data.pop() # removes the specified key and returns the value\n",
    "        if key is not present\n",
    "            it will throw error\n",
    "    popitem\n",
    "        emp_data.popitem() # will return last item from the dictionary\n",
    "\n",
    "5. keys\n",
    "    emp_data.keys() # lists all the keys\n",
    "    emp_data.values() # list all the values\n",
    "    emp_data.items()  # list all the key value pair as tuple\n",
    "    \n",
    "6. fromkeys\n",
    "    dict.fromkeys([1,2,3],20) # same value to each key \n",
    "    dict.fromkeys([1,2,3],[20,40,50]) # same list value to each key\n",
    "    dict.fromkeys(range(10),0)\n",
    "\n",
    "list(range(10))\n",
    "\n",
    "\n",
    "#### Set data type\n",
    "- mutable data type\n",
    "- cannot have mutable data type inside like list,dictionary, set\n",
    "- a={1,2,54,5,67,4}\n",
    "--  print(a,type(a))\n",
    "- is not a seq data type, hence indexing and slicing is not possible\n",
    "- to find out how many unique values are there\n",
    "- collection of unique value\n",
    "- will never allow duplication\n",
    "- a.add(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93d83a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Function and lambda function, 3rd feb\n",
    "\n",
    "**Types of argument**\n",
    "1. Postional argument\n",
    "- the order is imortant\n",
    "- number of parmeter should match with the number of argument\n",
    "e.g. def emp_detail(name,age,sal) # positional paramter\n",
    "print(emp_detail('xyz',23,36456)) # Postional argument\n",
    "2. keyword argument\n",
    "- the order is not important\n",
    "e.g. def emp_detail(name,age,sal)\n",
    "print(emp_detail(name='xyz',age=23,sal=36456))\n",
    "3. Default argument\n",
    "def emp_detail(name,age,sal,loc='goa',pin=324235)\n",
    "print(emp_detail(name='xyz',age=23,sal=36456))\n",
    "**always pass positional argument first, then pass keyword argument**\n",
    "\n",
    "**Global and local variable**\n",
    "global = available to all function\n",
    "local = available only to specific function, defined inside a function\n",
    "\n",
    "**variable length arguments**\n",
    "*args - variable length positional keywords and store it in form of a tuple\n",
    "** kwargs - variable length keyword argument and store it in the form of dictionary **\n",
    "e.g. def find_sum(*args):\n",
    "        print(args);\n",
    "        print(sum(args))\n",
    "    find_sum(23,12,43,56,67,45,765,787)\n",
    "\n",
    "e.g. def find_sum(** kwargs):\n",
    "        print(kwargs);\n",
    "    find_sum(a=23,b=12,c=43,d=56)\n",
    "    \n",
    "e.g. def emp_adder(** kwargs):\n",
    "        key=f'emp_{len(emp_data)+1}'\n",
    "        emp_data.setdefault(key,kwargs)\n",
    "    emp_adder(name='sadf', age=35, sal=34536)\n",
    "    \n",
    "**Return**\n",
    "- it is optional\n",
    "- default is None - if we do not return anything\n",
    "- returning multiple variable - it will be in the form of tuple - tuple packing\n",
    "- tuple unpacking \n",
    "e.g. def test():\n",
    "        a=5,b=3;\n",
    "        return a,b\n",
    "n1,n2 = test()\n",
    "\n",
    "**recursive function**\n",
    "- a function calling itself\n",
    "```\n",
    "def fact(x):\n",
    "    if x==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "print(fact(6))\n",
    "#fact(x)=x*fact(x-1)\n",
    "#fact(x-1)=(x-1)*fact(x-2)\n",
    "```\n",
    "**Lambda function**\n",
    "- function without a name\n",
    "- lambda fn can take n number of parameters, but only one expression\n",
    "\n",
    "creating lambda function  \n",
    "*1st method*\n",
    "```\n",
    " assign a lambda function to a variable \n",
    "x=lambda a,b:a+b # x is function\n",
    "x(2+6)\n",
    "```\n",
    "*2nd method*\n",
    "```\n",
    "x=(lambda a,b:a+b)(10,20) # x is variable\n",
    "x\n",
    "```\n",
    "*3rd method*\n",
    "```\n",
    "lambda function with a condition\n",
    "x=(lambda a:'even' if a%2==0)(10) # x is variable\n",
    "x\n",
    "```\n",
    "*4th method*\n",
    "lambda fn using list comprehension  \n",
    "to include for loop in a lambda function  \n",
    "```\n",
    "lst=[2,3,5,6,5,4,3,5]\n",
    "(lambda a:[i for in a if i%2==0])(lst)\n",
    "\n",
    "# if else condition\n",
    "a=lambda x:x if x>10 else 5\n",
    "a(12)\n",
    "\n",
    "(lambda x: x * 10 if x > 10 else (x * 5 if x < 5 else x))(11)\n",
    "```\n",
    "5th method\n",
    "as an ano  nymous function inside another function.\n",
    "```\n",
    "def myfunc(n):\n",
    "  return lambda a,b : a * n/b\n",
    "\n",
    "mydoubler = myfunc(4)\n",
    "\n",
    "print(mydoubler(13,2))\n",
    "```\n",
    "\n",
    "\n",
    "**Map, reduce, filter**\n",
    "*Map*\n",
    "takes two argument\n",
    "1. function\n",
    "2. seq\n",
    "\n",
    "syntax\n",
    "map(func,seq)\n",
    "```\n",
    "def square(x):\n",
    "    return x**2;\n",
    "lst=[1,2,3,4,5,6]\n",
    "list(map(square,lst))\n",
    "\n",
    "# using lambda\n",
    "list(map(lambda a:a**2,lst))\n",
    "\n",
    "# lambda function with two input variable\n",
    "list(map((lambda x,y:x+y),a,b))\n",
    "\n",
    "map will send variable in a list one by one\n",
    "\n",
    "```\n",
    "\n",
    "**Reduce**\n",
    "- function\n",
    "- seq\n",
    "from functools import reduce\n",
    "lst=[1,2,3,4,5,6,8]\n",
    "1,2,3,4,5,6\n",
    "3,3,4,5,6\n",
    "6,4,5,6\n",
    "reduce((lambda a,b:a+b),lst)\n",
    "\n",
    "\n",
    "**Filter**\n",
    "- function\n",
    "- seq\n",
    "the function should return bool values only  \n",
    "it filters those value to which func returns true\n",
    "list(filter((lambda a:a%2==0),lst))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29668037",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbddb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(x):\n",
    "    if x==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "print(fact(6))\n",
    "#fact(x)=x*fact(x-1)\n",
    "#fact(x-1)=(x-1)*fact(x-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62790ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "lst=[13,4,5,9,15,30,25,21,17]\n",
    "print(mean(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c90e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(range(20))\n",
    "out=[i for i in a if i%2==0]\n",
    "print(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07954bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['a',2,'r']\n",
    "a.reverse()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='hello'\n",
    "a.rjust(10,'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ceac5b-9d8d-4186-a8bd-e8776c934c04",
   "metadata": {},
   "source": [
    "### Regular expression\n",
    "\n",
    "```\n",
    ".       - Any Character Except New Line\n",
    "\\d      - Digit (0-9)\n",
    "\\D      - Not a Digit (0-9)\n",
    "\\w      - Word Character (a-z, A-Z, 0-9, _)\n",
    "\\W      - Not a Word Character\n",
    "\\s      - Whitespace (space, tab, newline)\n",
    "\\S      - Not Whitespace (space, tab, newline)\n",
    "\n",
    "\\b      - Word Boundary\n",
    "\\B      - Not a Word Boundary\n",
    "^       - Beginning of a String\n",
    "$       - End of a String\n",
    "\n",
    "[]      - Matches Characters in brackets\n",
    "[^ ]    - Matches Characters NOT in brackets\n",
    "|       - Either Or\n",
    "( )     - Group\n",
    "\n",
    "Quantifiers:\n",
    "*       - 0 or More\n",
    "+       - 1 or More\n",
    "?       - 0 or One\n",
    "{3}     - Exact Number\n",
    "{3,4}   - Range of Numbers (Minimum, Maximum)\n",
    "\n",
    "[abc] -  a,b or c\n",
    "[^abc] - any char other than abc\n",
    "[a-zA-Z] - small or cap only\n",
    "[0-9] - numbers only\n",
    "\n",
    "[ ]?\n",
    "[ ]*\n",
    "[ ]{n} - n times only\n",
    "[ ]{n,} - n or more times\n",
    "[ ]{n,m} - atleast n and max m\n",
    "```\n",
    "\n",
    "```\n",
    "# What you want to search ? compile\n",
    "\n",
    "pattern = re.compile('abc')\n",
    "\n",
    "# From what string you want to search ? find iter , findall\n",
    "\n",
    "match = pattern.findall(text_to_search)\n",
    "\n",
    "for i in match:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "\n",
    "# What you want to search ? compile\n",
    "\n",
    "pattern = re.compile('Mr')\n",
    "\n",
    "# From what string you want to search ? find iter , findall\n",
    "\n",
    "match = pattern.finditer(text_to_search)\n",
    "\n",
    "for i in match:\n",
    "    print(i)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53b403-ec8e-487d-88ef-873cbdaa9153",
   "metadata": {},
   "source": [
    "### Numpy 9th feb\n",
    "- array should contain homogenous data \n",
    "import numpy as np\n",
    "\n",
    "create array using list and tuple\n",
    "lst=[1,4,6,7,8,5]\n",
    "tup=(1,4,3,5,7,5,3)\n",
    "arr=np.array(lst)\n",
    "arr1=np.array(tup)\n",
    "\n",
    "#### attributes\n",
    "arr.size - number of elements in the array\n",
    "arr.shape\n",
    "arr.ndim\n",
    "\n",
    "for 3d matrix\n",
    "np.shape will give (depth,row,col)\n",
    "\n",
    "#### arange fn\n",
    "arange is like range, but returns array type and one dimentional\n",
    "\n",
    "#### datetime and timedelta\n",
    "np.arange(np.datetime64('2021-01-01'),np.datetime64('2021-01-30'),np.timedelta64(1,'D'))\n",
    "np.arange(np.datetime64('2021-01'),np.datetime64('2021-12'),np.timedelta64(1,'M'))\n",
    "a=np.datetime64('today')\n",
    "b=np.datetime64('now')\n",
    "\n",
    "\n",
    "#### linspace\n",
    "np.linspace(1,10,10)\n",
    "np.linspace(1,10,10,dtype=int)\n",
    "\n",
    "#### zeros and zeroslike\n",
    "np.zeros((3,4))\n",
    "np.zeros((3,4),dtype=int)\n",
    "np.zeros((depth,row,col)) - 3-dim matrix\n",
    "\n",
    "copies the shape of existing matrix\n",
    "np.zeros_like(lst) to create matrix like the list\n",
    "\n",
    "#### ones\n",
    "np.ones((3,5))\n",
    "\n",
    "#### identity\n",
    "- square matirx with diagonal element as 1\n",
    "np.identity(3)\n",
    "\n",
    "#### random\n",
    "np.random.rand(3,4) - uniform distribution between range 0-1\n",
    "np.random.randn(3,4)  - standard normal distributed,mean=0,std=1\n",
    "np.random.normal(mean,std,(shape))\n",
    "np.random.randint(1,49,6)  - integers from the \"discrete uniform\" distribution [,)\n",
    "\n",
    "#### misc\n",
    "np.count_nonzero(A)\n",
    "np.set_printoptions(precision=8,suppress=True)\n",
    "np.set_printoptions(edgeitems=10)\n",
    "B=np.delete(A,[2,3,4],0)\n",
    "np.pi\n",
    "\n",
    "\n",
    "print(np.sort(A))\n",
    "print(np.argsort(A))\n",
    "B=np.round(A,decimals=3)\n",
    "\n",
    "q=np.roots([4,5,1])\n",
    "print(q)\n",
    "p=np.poly1d([5,4,1])\n",
    "print(p.r)\n",
    "np.polyval(np.poly1d([4,5,1]),q)\n",
    "\n",
    "np.sign(A)\n",
    "\n",
    "#### polynomials\n",
    "p=np.poly1d([5,2,3])\n",
    "p.r for roots\n",
    "p.c for coeff\n",
    "p.order\n",
    "p(0.5)\n",
    "\n",
    "\n",
    "#### linalg\n",
    "np.linalg.det(A)\n",
    "a=np.array([[1,3],[3,10]]),x=np.linalg.eigvals(a)\n",
    "np.linalg.eig(A)\n",
    "np.linalg.inv(A)\n",
    "\n",
    "#### diagonal\n",
    "np.diag(np.arange(6))\n",
    "np.diag(x)\n",
    "\n",
    "#### saving and loading arrays\n",
    "np.save('arrays.npy',a)\n",
    "b=np.load('arrays.npy')\n",
    "\n",
    "np.savetxt('arrays.txt',a,fmt='%.2f')\n",
    "b=np.loadtxt('arrays.txt')\n",
    "\n",
    "** tolist **\n",
    "a=np.arange(12).reshape(3,4)\n",
    "b=a.tolist()\n",
    "\n",
    "#### reshape\n",
    "np.arange(12).reshape(2,6)\n",
    "np.arange(12).reshape(2,2,3)\n",
    "\n",
    "#### unistring\n",
    "<U11 - length all the string is less than 11, in an array\n",
    "\n",
    "#### infer\n",
    "helpful in fixing the rows and columns\n",
    "np.arange(12).reshape(2,-1)  -> -1 means infer\n",
    "\n",
    "#### Transpose\n",
    "arr.T\n",
    "\n",
    "#### arithmetic operation\n",
    "a=np.array(np.arange(10))\n",
    "b=np.array(np.arange(10))\n",
    "a+b -> add elementwise\n",
    "a-b\n",
    "a*b\n",
    "a/b\n",
    "a<5\n",
    "a[a<5] filter out where its true\n",
    "\n",
    "#### matrix multiplication\n",
    "a.dot(b)\n",
    "np.dot(A,B)\n",
    "\n",
    "#### unary operation\n",
    "-min()\n",
    "-max()\n",
    "-sum()\n",
    "-mean()\n",
    "for 2d\n",
    "a=np.arange(8).reshape(4,2)\n",
    "a.min(axis=0) figure out axis using test\n",
    "\n",
    "#### Statistical function\n",
    "- np.mean()\n",
    "- np.median()\n",
    "- np.mode()\n",
    "- np.std()\n",
    "- np.var()\n",
    "\n",
    "#### indexing and slicing\n",
    "- positive and negative indexing allowed\n",
    "2d - a[x][y] or a[x,y]\n",
    "a[[0,1,3],::] extract 0,1,3 rows and all columns\n",
    "\n",
    "#### deleting \n",
    "x = numpy.delete(x, (0), axis=0) #delete row\n",
    "x = numpy.delete(x, (0), axis=0) #delete column\n",
    "\n",
    "#### saving and loading\n",
    "np.save('arrays.npy',a)\n",
    "b=np.load('arrays.npy')\n",
    "np.savetxt('arrays.txt',a,fmt='%.2f')\n",
    "b=np.loadtxt('arrays.txt')\n",
    "np.savetxt('wig_games.csv',c,delimiter=',',fmt='%s')\n",
    "a=np.loadtxt('wig_games.csv',dtype='str',delimiter=',')\n",
    "a=np.genfromtxt('wig_games.csv',dtype='str',delimiter=',')\n",
    "#### iterating over an array\n",
    "for i in a:\n",
    "    print(i)\n",
    "2d\n",
    "for i in a:\n",
    "    for j in i:\n",
    "           print(j)\n",
    "#### flaten,ravel\n",
    "- coverts multi-dim array into one dimension\n",
    "- np.ravel(a)\n",
    "- a.flatten()\n",
    "\n",
    "#### splitting of an array\n",
    "np.split(a,how many split)\n",
    "np.split(a,6)\n",
    "user defined split\n",
    "np.split(a,[3,5,8])  - 0 and last position not needed\n",
    "\n",
    "np.vsplit(a,3)\n",
    "np.hsplit(a,3)\n",
    "\n",
    "\n",
    "\n",
    "#### intersect/common element\n",
    "A = np.arange(8).reshape(-1, 4)\n",
    "B = np.array([[9, 10, 11, 3],\n",
    "              [2, 8, 0, 9]]) \n",
    "np.intersect1d(A,B)\n",
    "\n",
    "#### vector stacking/cpncatination/append\n",
    "np.concatenate((a,b),axis=0)\n",
    "axis=0, rowise\n",
    "axis=1 columnwise\n",
    "hstack(row), vstack(column)\n",
    "np.hstack((a,b))\n",
    "\n",
    "A = np.arange(12).reshape(-1, 4)\n",
    "B = np.array([[4, 3, 7, 2],\n",
    "              [0, 5, 2, 6]])\n",
    "c=np.append(A,B,axis=0)\n",
    "\n",
    "#### padding\n",
    "a=np.ones((4,4))\n",
    "print(a)\n",
    "c=np.pad(a,1,constant_values=0)\n",
    "print(c)\n",
    "\n",
    "#### 3D\n",
    "from skimage import data \n",
    "image=data.astronaut()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.imshow(image[0:200,150:300])\n",
    "h1,h2=np.split(image,2,axis=1)\n",
    "plt.imshow(vstack((h1,h2)))\n",
    "\n",
    "** pillow **\n",
    "pip install Pillow\n",
    "from PIL import Image\n",
    "img=Image.open(Path)\n",
    "img\n",
    "dt = np.asarray(img)\n",
    "\n",
    "##### image and video\n",
    "images\n",
    "B&W in 2d\n",
    "color - 3d ppi\n",
    "\n",
    "video -  frames per second\n",
    "\n",
    "#### stats\n",
    "NUM_ROLLS = 1000\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6]\n",
    "sample = np.random.choice(values, NUM_ROLLS)\n",
    "print(sample)\n",
    "side, count = np.unique(sample, return_counts=True)\n",
    "\n",
    "np.repeat('*',4)\n",
    "\n",
    "**calculate mean,var,std of discrete rv**\n",
    "x=[0,1,2,3,4,5]\n",
    "p=[0.37,0.31,0.18,0.09,0.04,0.01]\n",
    "mu=np.average(x,weights=p)\n",
    "var=np.average((x-mu)**2,weights=p)\n",
    "print(var)\n",
    "print(np.sqrt(var))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa845a-2cd7-4a38-8e60-bf0c9cc34c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e92c9-e9d4-4e30-8c75-7b1173bea7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lst=[1,4,6,7,8,5]\n",
    "tup=(1,4,3,5,7,5,3)\n",
    "arr=np.array(lst)\n",
    "arr1=np.array(tup)\n",
    "print(type(tup),type(arr1))\n",
    "print(arr.shape)\n",
    "\n",
    "a=np.linspace(2,20,10)\n",
    "print(a,type(a))\n",
    "np.zeros((3,4))\n",
    "np.arange(10).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be5a3d-a4a2-42c4-8d63-f28928f8f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(2,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f253638-0d3e-430c-9401-cdcf56f6a316",
   "metadata": {},
   "source": [
    "### Pandas 1, 13th feb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20492626-cdda-47e0-bfc3-1dacbc0d86c6",
   "metadata": {},
   "source": [
    "pandas \n",
    "- can store heterogenous data\n",
    "- series 1d\n",
    "- dataframes 2d\n",
    "\n",
    "**different ways to create series dataframe**\n",
    "1 list\n",
    "2 tuple\n",
    "3 dict\n",
    "\n",
    "from list\n",
    "a=['a','b','c']\n",
    "a_ser = pd.Series(a)\n",
    "a_ser = pd.Series(a,index=[1,2,3])\n",
    "\n",
    "from array\n",
    "a=pd.Series(np.random.randn(5))\n",
    "\n",
    "from dict\n",
    "a={1:'a',2:'b'}\n",
    "pd.Series(a) # 1,2 are index, a,b are elements\n",
    "pd.Series(a,index=[1,3,4]) # 1 will be there, but 3,4 will have NaN values\n",
    "\n",
    "**dataframe to dict**\n",
    "x=df.head(5)\n",
    "x.to_dict()\n",
    "x.to_dict('list')\n",
    "\n",
    "**Indexing and slicing**\n",
    "- zero indexing\n",
    "- user defined index values\n",
    "\n",
    "a_ser[1]\n",
    "a_ser['a'] if a is user defined index\n",
    "\n",
    "**Dataframes**\n",
    "a=[3,6,89,5,3]\n",
    "pd.DataFrame(a,columns=['score'])\n",
    "\n",
    "creating dataframe using two or more list\n",
    "x=pd.DataFrames({'col1':a,'col2':b})\n",
    "\n",
    "syntax\n",
    "x=pd.DataFrame(my_dict)\n",
    "value has to be list, but not scalar\n",
    "stocks = {'PLW': [387.00], 'CDR': [339.5], 'TEN': [349.5], '11B': [391.0]}\n",
    "pd.DataFrame(stocks)\n",
    "\n",
    "if any list size is mismatch in count\n",
    "then convert each list into pd.Series and pass as dict\n",
    "\n",
    "**load dataset**\n",
    "a=pd.read_csv('datasets/ted_data.csv')\n",
    "\n",
    "**Basics**\n",
    "df.shape\n",
    "df.head()\n",
    "df.head(3) #top 3 rows\n",
    "df.tail()\n",
    "df.columns\n",
    "df.index\n",
    "df.info()\n",
    "df.describe()\n",
    "df.describe(include='object')\n",
    "df.describe(include='all')\n",
    "df[].min()\n",
    "df[].max()\n",
    "\n",
    "**indexing**\n",
    "df[['col1','col2']]\n",
    "df['col'][row]\n",
    "df.at[row,col]=x #to update any value\n",
    "df.index=list\n",
    "df[row:row_E]\n",
    "m[m==m.min()].index[0]  # to get the index of series\n",
    "\n",
    "**loc/iloc**\n",
    "df.loc[rowstart:stop:step,col_start:end:step]\n",
    "df.iloc[0:10:2,0:5]\n",
    "df.loc[df[col]==text] # to filter out column values\n",
    "\n",
    "df_new=df_old.assign()\n",
    "df_new=df_old.assign(new_col=x[])\n",
    "\n",
    "**apply and assign**\n",
    "df['col3']=df['col2'].apply(lambda x:1 if x>=0 else 0)\n",
    "\n",
    "**adding new columns**\n",
    "df['new_col']=0 or [1,2,3 size of row]\n",
    "df[['col1',col2']]=0  # adding multiple column\n",
    "apply can have an expression or a condition\n",
    "df['new_col']=df['old_col'].apply(lambda x:x*2) # old_col goes as x\n",
    "df['new_col']=df['old_col'].apply(lambda x:even if x%2==0 else odd)\n",
    "df.loc[(df['col2']>0.0) & (df['col2']<=1.0),:] # and condition\n",
    "\n",
    "**assign**\n",
    "df.assign(new_col=lambda x:x[]*x[])  # x is the dataframe df\n",
    "y.assign(d=y.b.apply(lambda x:x*5 if x<50 else x/5)+20)\n",
    "y['e']=y['b'].apply(lambda x:x*5 if x<50 else x/5)\n",
    "\n",
    "**delete col**\n",
    "del df['col']\n",
    "del [df[col1],df[col2]]\n",
    "\n",
    "df.drop(labels='col',axis=1,inplace=True)\n",
    "df.drop(columns=['col'],axis=1,inplace=True)\n",
    "df.drop(index=[row num], inplace=True)\n",
    "df=df.dropna()\n",
    "\n",
    "\n",
    "**replace a row**\n",
    "df[x] = [ values for all columns]\n",
    "df.loc[row_num]=[values]\n",
    "df.replace(old_val,new_val)\n",
    "df.replace({'col1':old_val,'col2':old_val}, 100)\n",
    "df.replace({'col1':old_val,'col2':old_val}, {'col1':new_val,'col2':new_val})\n",
    "\n",
    "df.replace({'Churn':{'Yes':1,'No':0}},inplace=True)\n",
    "y.replace({True:1,False:0})\n",
    "data['Gender'] = data['Gender'].map({'Male':0, 'Female':1})\n",
    "y.replace({'f':{True:1,False:0}})\n",
    "\n",
    "**rename**\n",
    "df.rename(columns={old:new_name})\n",
    "\n",
    "**iterating over df**\n",
    "-iteritems\n",
    "-iterrows\n",
    "-itertuples\n",
    "for i in df.itertuples():\n",
    "    print(i)\n",
    "    if i.col==x:\n",
    "        print(i.col2)\n",
    " \n",
    "**correlation**\n",
    "df.corr(numeric_only=True)\n",
    " \n",
    "**datetime**\n",
    "date_range(start,end,period,freq)\n",
    "pd.date_range(start='2020-01-01',end='2020-01-31')\n",
    "pd.Series(date_ranges)\n",
    "[Google sheet](https://docs.google.com/spreadsheets/d/1g8nziA3PEazKqC6ia3Lj1fypHltdpsArhwu0hpQRG20/edit?usp=sharing)\n",
    "[date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html)\n",
    "[freq Aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "pd.Timestamp(\"2014-08-01 13:00\")\n",
    "pd.Timestamp(\"2018-01-05\")\n",
    "pd.Timedelta(days=1)\n",
    "pd.Timedelta(1, \"d\")\n",
    "td.pd.Timedelta(42, unit='s')\n",
    "td.seconds\n",
    "pd.DateOffset(days=1)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
    "pd.Timestamp('1/1/2023')+pd.Timedelta(minutes=1)\n",
    "\n",
    "\n",
    "ts = pd.Timestamp(2020, 3, 14)\n",
    "ts.day_of_week\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"day_name\"] = df[\"date\"].dt.dayofweek\n",
    "\n",
    "y=pd.date_range(start='2020-01-01',end='2020-12-31')\n",
    "z=y[y.dayofweek==0]\n",
    "\n",
    "x=pd.date_range(start='2021-03-01',periods=31)\n",
    "y=pd.DataFrame({'day':x,'dayofyear':x.dayofyear})\n",
    "\n",
    "**Plotting**\n",
    "https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import matplotlib.pyplot as plt\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "df=pd.DataFrame(data_dict)\n",
    "df['normal'].plot(kind='hist',bins=20)\n",
    "df['normal'].plot.hist(bins=20)\n",
    "kindstr\n",
    "The kind of plot to produce:\n",
    "\n",
    "‘line’ : line plot (default)\n",
    "\n",
    "‘bar’ : vertical bar plot\n",
    "\n",
    "‘barh’ : horizontal bar plot\n",
    "\n",
    "‘hist’ : histogram\n",
    "\n",
    "‘box’ : boxplot\n",
    "\n",
    "‘kde’ : Kernel Density Estimation plot\n",
    "\n",
    "‘density’ : same as ‘kde’\n",
    "\n",
    "‘area’ : area plot\n",
    "\n",
    "‘pie’ : pie plot\n",
    "\n",
    "‘scatter’ : scatter plot (DataFrame only)\n",
    "\n",
    "‘hexbin’ : hexbin plot (DataFrame only)\n",
    "\n",
    "s = pd.Series([1, 3, 2])\n",
    "s.plot.line()\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.line(humidity_by_month)\n",
    "fig.show()\n",
    "fig = px.line(humidity_by_month,template='plotly_dark')\n",
    "https://plotly.com/python/marginal-plots/\n",
    "\n",
    "**counting missing values**\n",
    "df.isna().sum()\n",
    "\n",
    "value_counts() function returns Series containing counts of unique values. The resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default.\n",
    "4\n",
    "\n",
    "count() is used to count the number of non-NA/null observations across the given axis. It works with non-floating type data as well.\n",
    "df['TotalCharges'].value_counts()[0:3].index\n",
    "\n",
    "df.loc[df['TotalCharges']==' ','TotalCharges']=np.nan\n",
    "df['TotalCharges']=df['TotalCharges'].astype(float)\n",
    "df.loc[df['TotalCharges'].isna(),'TotalCharges']=df['TotalCharges'].median()\n",
    "\n",
    "df['engine'].value_counts(normalize=True)*100\n",
    "\n",
    "**Download**\n",
    "%%bash\n",
    "wget -q https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv\n",
    "\n",
    "**select dtype**\n",
    "df_raw.select_dtypes(include='object')\n",
    "df_raw[i]=df_raw[i].astype('category')\n",
    "\n",
    "**dummies**\n",
    "df_dummies=df_raw.select_dtypes(include='category')\n",
    "pd.get_dummies(df_dummies,drop_first = True)\n",
    "y=pd.get_dummies(df.select_dtypes(include='category'),drop_first=True)\n",
    "y=pd.get_dummies(df['size'])\n",
    "\n",
    "**Encoder** # works better\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "le.fit(df['bought'])\n",
    "df['bought']=le.transform(df['bought'])\n",
    "df['bought']=le.inverse_transform(df['bought'])\n",
    "\n",
    "**OneHotEncoder**\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "le_oh = OneHotEncoder(sparse_output=False)\n",
    "x=le_oh.fit_transform(df[['size']])\n",
    "\n",
    "**replace a row**\n",
    "df[x] = [ values for all columns]\n",
    "df.loc[row_num]=[values]\n",
    "df.replace(old_val,new_val)\n",
    "df.replace({'col1':old_val,'col2':old_val}, 100)\n",
    "df.replace({'col1':old_val,'col2':old_val}, {'col1':new_val,'col2':new_val})\n",
    "\n",
    "df.replace({'Churn':{'Yes':1,'No':0}},inplace=True)\n",
    "y.replace({True:1,False:0})\n",
    "data['Gender'] = data['Gender'].map({'Male':0, 'Female':1})\n",
    "y.replace({'f':{True:1,False:0}})\n",
    "\n",
    "le=LabelEncoder()\n",
    "le.fit(df.fueltype)\n",
    "y=le.transform(df.fueltype)\n",
    "\n",
    "**scalar**\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler().fit(df[['weight']])\n",
    "x=ss.transform(df[['weight']])\n",
    "\n",
    "**test_train_split**\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4a6c2-9ac2-4310-a611-5fbc92835aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas_datareader\n",
    "**linux**\n",
    "%%bash\n",
    "head -5 dataframe.csv\n",
    "\n",
    "**set options**\n",
    "[options](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html)\n",
    "pd.get_option(\"display.precision\")\n",
    "pd.set_option(\"display.precision\",2)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "google.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08380f54",
   "metadata": {},
   "source": [
    "#### pandas 3, 14th feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sorting\n",
    "df=pd.read_csv('datasets/unsorted_imdb_rating.csv')\n",
    "df.sort_values('star_rating')\n",
    "df.sort_values(by=df.columns[0])\n",
    "df.at[5,'star_rating']=8.9\n",
    "df.sort_values(by=['star_rating','duration']) # the values of star rating which was repeated, got sorted by duration\n",
    "df.sort_values(by=['star_rating','duration'],ascending=[True,False]) # sorting duration in descending order\n",
    "\n",
    "# Find the number of levels in each column\n",
    "data.nunique()\n",
    "data['col'].unique()\n",
    "\n",
    "## concatination\n",
    "pd.concat([india_weather,us_weather])\n",
    "pd.concat([india_weather,us_weather],ignore_index=True)\n",
    "df.reset_index()\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "## multiplevel concatenation\n",
    "df =pd.concat([india_weather,us_weather],keys=['India','US'])\n",
    "df.loc['US']\n",
    "\n",
    "## merge\n",
    "pd.merge(df1,df2) # default inner join, how='outer','left','right'\n",
    "pd.merge(df1,df2,how='outer', indicator=True) # with indicator\n",
    "\n",
    "## handling missing/NaN values\n",
    "df.isnull() # to track for any null values\n",
    "df.isnull().sum()\n",
    "df.fillna(100) # fill entire dataframe null value with 100\n",
    "df.fillna({'temperature':30, 'humidity':200})\n",
    "df.fillna({'temperature':df['temperature'].mean(), 'humidity':df['humidity'].mode()[0]})  # fill with formalae\n",
    "df.dropna()\n",
    "df.dropna(thresh=2) # atleast 2 (2 or more) real values in a row\n",
    "\n",
    "## dataset\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "## groupby\n",
    "df = pd.read_csv('datasets/weather_by_cities_group_by.csv')\n",
    "df['city'].unique() # to get unique values\n",
    "g=df.groupby('city')\n",
    "list(g) # to see the groups\n",
    "g.max()['temperature']   # find stats of columns in each group\n",
    "g.get_group('new york')\n",
    "g=df_google.groupby(['Year','Month'])\n",
    "print(g.mean(numeric_only = True))\n",
    "\n",
    "X_train.insert(loc=0,column='intercept',value=np.ones(X_train.size))\n",
    "\n",
    "# creating dummies for gender\n",
    "data['Gender'] = data['Gender'].map({'Male':0, 'Female':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdb746-7dbb-4a96-b58a-f36ed4aa121e",
   "metadata": {},
   "source": [
    "### pandas EDA\n",
    "\n",
    "- df.read_csv()\n",
    "- df.head()\n",
    "- df.info()\n",
    "- df.nunique()\n",
    "- df.duplicated()\n",
    "- df.query('c_name==\"audi\"')\n",
    "- X_train.insert(loc=0,column='intercept',value=np.ones(X_train.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f9f49-fa32-4f8a-b8ab-16b4df353695",
   "metadata": {},
   "source": [
    "#### Modules, File handling 6th feb\n",
    "\n",
    "**Iterators**\n",
    "lst=[1,3,5,6]\n",
    "my_iter = iter(lst)\n",
    "print(next(my_iter))\n",
    "\n",
    "**Modules**\n",
    "- a python file with extension .py\n",
    "\n",
    "**Types of modules**\n",
    "- builtin modules - math, os, sys, datetime\n",
    "- user defined - defined/implemented by user\n",
    "\n",
    "**global namespace**\n",
    "print(dir()) - user defined functions get added here in the list\n",
    "\n",
    "\n",
    "**methods of importing modules**\n",
    "- 1st method\n",
    "print(dir(),end=\\n\\n)\n",
    "import math\n",
    "print(dir())\n",
    "\n",
    "- 2nd method\n",
    "from math import *\n",
    "-a ll function will go to global memory\n",
    "\n",
    "- 3rd method\n",
    "from math import sqrt\n",
    "\n",
    "- 4th method\n",
    "Aliasing\n",
    "import math as mt\n",
    "\n",
    "**creating own custom modules**\n",
    "create func in a text file\n",
    "save it as a .py file in current folder or in sys.path\n",
    "import filename as fn # to call the func\n",
    "print(dir(fn))\n",
    "\n",
    "**import sys**\n",
    "print(sys.path)\n",
    "sys.path.append(\"location of programme file\")\n",
    "\n",
    "**writing the test cases**\n",
    "\n",
    "**__name__**\n",
    "\n",
    "write function and testcases in the same file.\n",
    "put test cases under if __name__ == '__main__':\n",
    "the test cases will not execute if its called as module.\n",
    "it will run only when the file is run directly by itself\n",
    "\n",
    "\n",
    "**File handling**\n",
    "two types of file\n",
    "1. text file - csv,excel\n",
    "2. binary file - images, videos, audio\n",
    "\n",
    "points to keep in mind while handling files\n",
    "- first open the file\n",
    "    var = open('path/name.ext','mode to open')\n",
    "- closing the file\n",
    "    var.close() to to save the changes\n",
    "- data read from file is always in the form of string\n",
    "\n",
    "- mode of operation for text file \n",
    "    - read mode 'r'\n",
    "    - write mode 'w'\n",
    "    - append -'a'\n",
    "    - read and write 'r+'\n",
    "    - write and read 'w+'\n",
    "    - append and read 'a+'\n",
    "    \n",
    " - mode of operation for binary file \n",
    "    - read mode 'rb'\n",
    "    - write mode 'wb'\n",
    "    - append -'ab'\n",
    "    - read and write 'r+b'\n",
    "    - write and read 'w+b'\n",
    "    - append and read 'a+b'\n",
    "    \n",
    " - function on file object\n",
    "     - read()\n",
    "     - write()\n",
    "     - tell() # tells the position of the cursor\n",
    "     - seek() # movest he cursor to specified location\n",
    "     \n",
    "     \n",
    "- mode of operation\n",
    "    - if the file do not exit, will throw filenotfound error\n",
    "    - if the file is found, it will open the file and keep the cursor ar the beginning of the file\n",
    "    \n",
    "**read** \n",
    "```\n",
    "f=open('../Assignment/test.txt','r')\n",
    "a=f.tell()\n",
    "f.seek(7)\n",
    "b=f.read()\n",
    "print(b)\n",
    "f.close()\n",
    "```\n",
    "\n",
    "**write**\n",
    "if file donot exist, it will create new file\n",
    "if exist, it will delete old data\n",
    "```\n",
    "f=open('../Assignment/test_w.txt','w')\n",
    "f.write('Tarun')\n",
    "f.seek(2)\n",
    "f.write(' kumar')\n",
    "f.close()\n",
    "```\n",
    "\n",
    "**append**\n",
    "if file donot exist, it will create new file\n",
    "if exist, it will keep the cursor ar the last char\n",
    "you canot (never)overwrite the existing data\n",
    "always writes the data at the end\n",
    "```\n",
    "f=open('../Assignment/test_w.txt','a')\n",
    "f.write('Tarun')\n",
    "f.seek(2)\n",
    "f.write(' kumar')\n",
    "f.close()\n",
    "\n",
    "```\n",
    "\n",
    "**methods in read file function**\n",
    "- read() # reads the completes data and gives data as string\n",
    "- seek(int)\n",
    "- read(6) # reads specified number of char\n",
    "- realine # reads the current line from the cursor\n",
    "- readlines() # read the complete lines, and returns each line as list\n",
    "\n",
    "**methods in write file function**\n",
    "- write(str)\n",
    "- writelines(['line1','line2','line3'])\n",
    "\n",
    "\n",
    "- read().split() to get number of words\n",
    "-readlines() to get number of lines\n",
    "\n",
    "**png to jpg**\n",
    "f=open('test.png','rb')\n",
    "data=f.read();\n",
    "f1=open('test.jpg',wb)\n",
    "f1.write(data)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc5cb6-1ad5-4f15-8bcb-61f650b45326",
   "metadata": {},
   "source": [
    "### Exception handling\n",
    "\n",
    "**types of errors**\n",
    "- compile time error # syntax, indentation, \n",
    "- run time error # division by zero, type error name\n",
    "- logical error # these are made by users\n",
    "\n",
    "Note: exception handling can handle runtime error\n",
    "\n",
    "print(dir(__builtins__))\n",
    "\n",
    "**keywords**\n",
    "- try - # the code which will give error\n",
    "- except # the backup code, if try block fails\n",
    "- else  # execution will go to else if try block doesnt raise an error\n",
    "- finally # whether try fails or not, even if except fails to execute, finally will execute\n",
    "- raise  # custom error trigger e.g. raise typeerror ('personal message')\n",
    "\n",
    "**display reason for exception**\n",
    "try:\n",
    "    print(a/b)\n",
    "except exception as e:\n",
    "    print(e)\n",
    "except divisionbyzero as e:\n",
    "    print('backup code for division by zero error')\n",
    "\n",
    "try:\n",
    "    print(a/b)\n",
    "except ZeroDivisionError as e:\n",
    "    print(\"check the value of b\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('check the code')\n",
    "finally:\n",
    "    print(\"done\")\n",
    "    \n",
    "**user defined error**\n",
    "class personal_error(Exception):\n",
    "    def __init__(self,msg):\n",
    "        self.msg=msg\n",
    "\n",
    "class myerror(Exception):\n",
    "    def __init__(self):\n",
    "        self.msg=\"my type of error\"\n",
    "    def __str__(self):\n",
    "        return self.msg\n",
    "raise myerror\n",
    "\n",
    "class myerror(Exception):\n",
    "    def __init__(self,msg):\n",
    "        self.msg=msg\n",
    "    def __str__(self):\n",
    "        return self.msg\n",
    "raise myerror(\"i am raising error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fdd461-6371-413a-92d2-82df144a6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "'''\n",
    "%Y  Year with century as a decimal number.\n",
    "%m  Month as a decimal number [01,12].\n",
    "%d  Day of the month as a decimal number [01,31].\n",
    "%H  Hour (24-hour clock) as a decimal number [00,23].\n",
    "%M  Minute as a decimal number [00,59].\n",
    "%S  Second as a decimal number [00,61].\n",
    "%z  Time zone offset from UTC.\n",
    "%a  Locale's abbreviated weekday name.\n",
    "%A  Locale's full weekday name.\n",
    "%b  Locale's abbreviated month name.\n",
    "%B  Locale's full month name.\n",
    "%c  Locale's appropriate date and time representation.\n",
    "%I  Hour (12-hour clock) as a decimal number [01,12].\n",
    "%p  Locale's equivalent of either AM or PM.\n",
    "'''\n",
    "time.strftime('%Y-%m-%d %H-%M-%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1081c71-5b90-4849-9a9c-4362cb3e6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../Assignment/test.txt','r')\n",
    "a=f.tell()\n",
    "f.seek(7)\n",
    "b=f.read()\n",
    "print(b)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9cf1c-76ff-424f-905f-2b6f8195043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../Assignment/test_w.txt','a')\n",
    "f.write('Tarun')\n",
    "f.seek(2)\n",
    "f.write(' kumar')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c72f69-978f-4145-8027-138c655ca0f5",
   "metadata": {},
   "source": [
    "#### OpenCV/computer vision\n",
    "\n",
    "pip install opencv-python   \n",
    "import cv2   \n",
    "```\n",
    "%mkdir model\\\n",
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
    "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
    "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e9ee0-13dd-4b4d-b8b3-c73a2431cd3d",
   "metadata": {},
   "source": [
    "### Getting datasets\n",
    "**seaborn**\n",
    "import seaborn as sns\n",
    "sns.get_dataset_names()\n",
    "data_df=sns.load_dataset('dataset_name')\n",
    "\n",
    "**sklearn inbuilt**\n",
    "import sklearn.datasets as ds\n",
    "data_df,t=ds.load_iris(as_frame=True,return_X_y=True)\n",
    "data_df['target']=t\n",
    "\n",
    "**fetchOpenML**\n",
    "d,t=ds.fetch_openml(data_id=50,return_X_y=True,as_frame=True)\n",
    "data_id - https://www.openml.org/search?type=data&sort=runs&status=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378f759-fe2a-419a-893a-eca0b4ad36b9",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Statsmodels\n",
    "import statsmodels.api as sm  \n",
    "# logreg=sm.Logit(ytrain,xtrain).fit()  # logistic regression\n",
    "# SLR_mod=sm.OLS(y_train_slr, X_train_slr).fit()  # Linear regression\n",
    "\n",
    "# tools\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "# VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "## sklearn\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "rmse=np.sqrt(mean_squared_error)\n",
    "\n",
    "# model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor # import SGDRegressor from sklearn to perform linear regression with stochastic gradient descent\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    X_scaler = StandardScaler()\n",
    "    num_scaled = X_scaler.fit_transform(df_num)\n",
    "    df_num_scaled = pd.DataFrame(num_scaled, columns = df_num.columns)\n",
    "    \n",
    "import statsmodels.api as sm\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    model = sm.OLS(Y_train,X_train).fit()\n",
    "    model.summary()\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "from sklearn.linear_model import LinearRegression\n",
    "    linreg = LinearRegression()\n",
    "    MLR_model = linreg.fit(X_train, y_train)\n",
    "    test_pred = MLR_model.predict(X_test)\n",
    "    # score() returns the R-squared value\n",
    "    MLR_model.score(X_train, y_train)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "    sgd = SGDRegressor(random_state = 10)\n",
    "    linreg_with_SGD = sgd.fit(X_train, y_train)\n",
    "    test_pred = linreg_with_SGD.predict(X_test)\n",
    "    model.coef_\n",
    " \n",
    "from sklearn.linear_model import Ridge\n",
    "    # 'alpha' assigns the regularization strength to the model\n",
    "    # 'max_iter' assigns maximum number of iterations for the model to run\n",
    "    ridge = Ridge(alpha = 1, max_iter = 500)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "from sklearn.linear_model import Lasso\n",
    "    lasso = Lasso(alpha = 0.01, max_iter = 500)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "from sklearn.linear_model import ElasticNet\n",
    "    # 'alpha' assigns the regularization strength to the model\n",
    "    # 'l1_ratio' is the ElasticNet mixing parameter\n",
    "    # 'l1_ratio = 0' performs Ridge regression\n",
    "    # 'l1_ratio = 1' performs Lasso regression\n",
    "    # pass number of iterations to 'max_iter'\n",
    "    enet = ElasticNet(alpha = 0.1, l1_ratio = 0.01, max_iter = 500)\n",
    "    enet.fit(X_train, y_train)\n",
    "    \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    tuned_paramaters = [{'alpha':[1e-15, 1e-10, 1e-8, 1e-4,1e-3, 1e-2, 0.1, 1, 5, 10, 20, 40, 60, 80, 100]}]\n",
    "    tuned_paramaters_enet = [{'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 20, 40, 60],\n",
    "                      'l1_ratio':[0.0001, 0.0002, 0.001, 0.01, 0.1, 0.2]}]\n",
    "    ridge = Ridge()\n",
    "    ridge_grid = GridSearchCV(estimator = ridge,\n",
    "                          param_grid = tuned_paramaters,\n",
    "                          cv = 10)\n",
    "    ridge_grid.fit(X_train, y_train)\n",
    "    print('Best parameters for Ridge Regression: ', ridge_grid.best_params_, '\\n')\n",
    "    test_pred = ridge_grid.predict(X_test)\n",
    "    \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = df.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    vif.round(1).sort_values(by='VIF', ascending=False)\n",
    "    vif_values_less_than_20 = vif_values[vif_values['VIF']<20]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[statsmodel](https://www.statsmodels.org/stable/api.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c4eba-118b-455d-8950-cd6d937f49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression models\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "\n",
    "#### metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a3120-13c9-4051-91c2-f1c558a63493",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binary classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#### metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbea4c8-38aa-4f49-b683-5fe14d56a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### object creation\n",
    "classifier_lr = LogisticRegression(random_state = 0,C=10,penalty= 'l2') \n",
    "classifier_svc = SVC(kernel = 'linear',C = 0.1)\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'entropy')\n",
    "classifier_rf = RandomForestClassifier(max_depth = 2,random_state = 0)\n",
    "classifier_knn = KNeighborsClassifier(leaf_size = 7, n_neighbors = 3,p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf55cfe-4130-4663-809e-850aab1c35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### multiclass classification models\n",
    "# https://www.kaggle.com/code/spalatov/eda-multiclass-classification\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#### metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ec819-bfe5-408f-a972-f807f426227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### misc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report,f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc959fda-3776-406f-98fc-c20305f9f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ROC\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model(classifier):\n",
    "    \n",
    "    classifier.fit(x_train,y_train)\n",
    "    prediction = classifier.predict(x_test)\n",
    "    print(\"ACCURACY : \",'{0:.2%}'.format(accuracy_score(y_test,prediction))) \n",
    "    print(\"CROSS VALIDATION SCORE : \",'{0:.2%}'.format(cross_val_score(classifier,x_train,y_train,cv = 10,scoring = 'accuracy').mean()))\n",
    "    print(\"ROC_AUC SCORE : \",'{0:.2%}'.format(roc_auc_score(y_test,prediction)))\n",
    "    plot_roc_curve(classifier, x_test,y_test)\n",
    "    plt.title('ROC_AUC_PLOT')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cce9b0-8165-425d-b6d9-016e92aeb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        img = PImage.open(path + image)\n",
    "        loadedImages.append(img)\n",
    "\n",
    "    return loadedImages\n",
    "\n",
    "path = \"D:\\\\data\\\\Skin cancer ISIC The International Skin Imaging Collaboration\\\\Train\\\\melanoma\\\\\"\n",
    "\n",
    "# your images in an array\n",
    "imgs = loadImages(path)\n",
    "\n",
    "for img in imgs:\n",
    "    # you can show every image\n",
    "    img.show()\n",
    "    \n",
    "\n",
    "# imageio\n",
    "import imageio.v3 as iio\n",
    "\n",
    "im = iio.imread(\"D:\\data\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\\melanoma\\ISIC_0000141.jpg\")\n",
    "plt.imshow(im)\n",
    "\n",
    "#glob\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "for image_path in glob.glob(\"D:\\data\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\\melanoma\\ISIC_0000141.jpg\"):\n",
    "    im = imageio.imread(image_path)\n",
    "    plt.imshow(im)\n",
    "    print (im.shape)\n",
    "    print (im.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebc881-f13d-4eb9-899e-9fb46c1d57a7",
   "metadata": {},
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1b3a3-ad67-4620-a7b1-4745b327204d",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "\n",
    "filling with mode\n",
    "df = df.fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b683ffe-4bd1-4cea-b9c0-c89a507da450",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seaborn\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(df.Age)\n",
    "plt.subplot(2,2,4)\n",
    "sns.histplot(df.Age)\n",
    "sns.barplot(x = \"Coefficient\", y = \"Variable\", data = sorted_coeff)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)\n",
    "sns.distplot(df[col], label=\"skew: \")\n",
    "\n",
    "sns.heatmap(cm_df,annot = True)\n",
    "\n",
    "sns.pairplot(cars_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11efd2",
   "metadata": {},
   "source": [
    "### Matplotlib and seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "#### matplotlib does only 2D plot\n",
    "fmt = '[marker][line][color]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ac32e-50a0-43a7-ad61-884e83e1d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efea5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wd = [1,2,3,4,5,6,7]\n",
    "temp = [23,24,26,29,32,27,23]\n",
    "\n",
    "#plt.plot(wd,temp,c='g',ls='--',marker='x')\n",
    "plt.plot(wd,temp,'rx--')\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('temperature')\n",
    "plt.title('weather data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "day=[1,2,3,4,5,6,7]\n",
    "max_T = np.round(np.random.uniform(30,38,7),2)\n",
    "min_T = np.round(np.random.uniform(20,30,7),2)\n",
    "avg_T = np.round(np.random.uniform(26,34,7),2)\n",
    "plt.plot(day,max_T,label='Max Temp')\n",
    "plt.plot(day,min_T,label='Min Temp')\n",
    "plt.plot(day,avg_T,label='Avg Temp')\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('temperature')\n",
    "plt.title('weather data')\n",
    "plt.legend(loc=1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar graph\n",
    "# one variable should be categorical\n",
    "comp = ['google','fb','ms','amz']\n",
    "stock = [234,345,234,545]\n",
    "plt.bar(comp,stock)\n",
    "plt.ylabel('stock price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = ['google','fb','ms','amz']\n",
    "stock = [234,345,234,545]\n",
    "plt.barh(comp,stock)\n",
    "plt.ylabel('stock price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "#normal-80-100\n",
    "#prediabetic 101-140\n",
    "#diabetic 141-above\n",
    "bld_sugar = [123,130,125,140,120,124,89,80,100,150,145,159]\n",
    "plt.hist(bld_sugar) # system generated bins\n",
    "plt.hist(bld_sugar,bins=[70,100,140,170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3276e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "men=[113,85,90,150,149,88,93,115,135,80,77,82,129]\n",
    "women = [67,98,89,120,133,150,84,69,89,79,120,112,100]\n",
    "plt.hist([men,women],bins=[70,100,140,170],label=['Men','Women'])\n",
    "plt.legend()\n",
    "#plt.hist(women,bins=[70,100,140,170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie chart\n",
    "exp=[124,245,150,320]\n",
    "spen_on=['car','bike','phone','rent']\n",
    "plt.pie(exp,labels=spen_on,radius=2,autopct='%0.02f%%')\n",
    "plt.show() # to get rid of printed data in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71addf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "#plt.scatter(df['day'],df['temperature'])\n",
    "# Subplot\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(bld_sugar,bins=[70,100,140,170])\n",
    "plt.subplot(2,2,2)\n",
    "plt.pie(exp,labels=spen_on,radius=2,autopct='%0.02f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59158e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('datasets/plot_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae931a-2c92-40c8-8c6b-c93029a6be8b",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "#### most used plots\n",
    "**Categorical**\n",
    "- sns.histplot\n",
    "- sns.countplot\n",
    "- sns.distplot\n",
    "- sns.displot\n",
    "- sns.heatmap\n",
    "- sns.boxplot\n",
    "- sns.scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset('tips')\n",
    "df['time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78772def",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='total_bill',y='tip',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74641764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='total_bill',y='tip',data=df,hue='smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='total_bill',y='tip',data=df,hue='smoker',size='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df67ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02548ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='total_bill',y='tip',data=df,hue='smoker',size='time',style='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='total_bill',y='tip',data=df,col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db294c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='total_bill',y='tip',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='day',y='total_bill',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='day',y='total_bill',data=df,jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16663e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='day',y='total_bill',data=df,kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='day',y='total_bill',data=df,kind='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daba275",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randn(100)\n",
    "sns.displot(x,kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x='total_bill',data=df,kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50409db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358efd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sex',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabc997-f323-4a2e-990e-71a80925bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948fb9-8cf7-4e9d-b1ac-308d4f771aad",
   "metadata": {},
   "source": [
    "## Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c618d-6861-4d1f-b8c7-8b22dea95274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075b549-9ad5-45a0-a56b-d84804acbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.poisson(3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b236701-8c8f-4a0f-8e1f-9a34d3cf4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.poisson(3.6,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4addb53-2c55-41c4-84a0-2b134677ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.countplot(x=a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842981e1-dfab-41aa-9521-a77f99a4bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e30e75-af4c-4785-93a5-923c1b55eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.pmf(7,3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5478ab-a06b-4ab2-a272-d6f84a27e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.cdf(7,3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20830ed-3a11-43f5-ae14-8626624772d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.mean(3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cea8a-1c69-4582-b9df-07e2d14017be",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.var(3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95056dd0-028d-4156-88e0-71eed32fecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.std(3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c66c52-d680-4149-8c64-d223fbf985ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xax=np.arange(11)\n",
    "print(xax)\n",
    "b=poisson.pmf(xax,3.6)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc8682-f0bb-4089-a8ff-ec9049692a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=xax,y=b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8cc2b-41d3-4282-a86b-3eef7081a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "xax=np.arange(11)\n",
    "print(xax)\n",
    "b=poisson.cdf(xax,3.6)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de923d4-5c80-4e76-9d40-8c2e01e61335",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=xax,y=b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632a882-4bfd-499a-9682-5f04c78f3476",
   "metadata": {},
   "source": [
    "# Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9681ae-b0e2-4e98-ac6d-2e46d1cbe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.normal(100,2,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29ffd3-38c2-4b5c-9217-80910df9a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.histplot(x=a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb88870-bf1e-498c-875b-820467e9489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=a,kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400b255-2463-4adc-9660-75441feaae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((a>98)&(a<102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315cdc6-d89b-4549-bbc3-7af63a4246c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd15d3-eb25-4f08-b18e-a7732439b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.sf(153,150,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19d751-c7a7-4c06-811d-4121dbf42e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.linspace(144,156,1300)\n",
    "b=norm.pdf(a,150,2)\n",
    "\n",
    "sns.lineplot(x=a,y=b)\n",
    "plt.axvline(152,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e96c6-2d11-4c68-bb07-4bbee59a1e1e",
   "metadata": {},
   "source": [
    "# Bniomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27de0db-516e-4fcb-8c2a-7d14a64d52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd97ff-611f-4d33-97a5-d0db39079f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binom.pmf(r,n,p)\n",
    "binom.pmf(2,5,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f84c75-84e1-4442-8664-1238e188b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(3,10,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9edeb3-9c72-43b1-95b3-b734c8c8785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.pmf(12,20,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749151d-a660-499c-92c9-3f92b911dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(binom.cdf(8,20,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8301e-a836-4fea-85d8-cb8158274744",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-binom.cdf(11,20,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b768b0-cc67-4be9-8215-947ef977bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-binom.cdf(6,10,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7ba70-d37e-4aa7-9622-12be6dbd3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.mean(25,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c6e48-81d9-4227-898e-bcac11f307d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.var(25,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44864687-2b1f-45ba-bdf2-a07fae49c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.std(25,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f7117-a450-4176-9362-cc8f1f9e4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(16,20,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06107272-385d-4962-a866-13808448885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.pmf(6,15,0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efdc75-cb27-4678-bd4e-dfd8e455ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.pmf(0,15,0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d9468-930c-4b56-9b1a-59dff9f07f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-binom.cdf(9,15,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752966b-da7d-47cb-81e4-953c44e52678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23919e0-bef0-4c4a-8780-859dfe741087",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson.pmf(4,1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b6a18-46da-4538-9920-49a4364a7511",
   "metadata": {},
   "source": [
    "Typically a p value of 0.05 (or 5%) is thought of as \"good\" or \"statistically significant,\" as there's only a 5% or less chance that these results aren't valid.\n",
    "\n",
    "You should only be adding features when you have an argument as to why they'd affect the outcome. Bad features have a tendency to not only ruin your entire regression's p value, they also screw around with features that are actually valid and good!\n",
    "\n",
    "Your pseudo R-squared is on a scale from 0 to 1, with higher values meaning a better fit. Unlike linear regression's R-squared, though, you can't use it to say \"we're explaining such-and-such of the variation.\" You can only use it to say \"this model is better than that model.\"\n",
    "\n",
    "The most important measure in your regression is going to be your p value, which is used to measure statistical significance (aka the chance your data is a happy accident, not actually meaningful). Traditionally 0.05 is the cutoff, which means there's a less than 5% chance that your findings were made by chance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
